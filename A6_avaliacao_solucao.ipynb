{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"docXpala avaliacao solucao.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Fl_MmAV7LwiY"},"source":["# <font color=\"blue\"> MBA em Ciência de Dados</font>\n","# <font color=\"blue\">Técnicas Avançadas para Captura e Tratamento de Dados</font>\n","\n","## <font color=\"blue\"> Matriz Documento $\\times$ Palavras - Bag of Words</font>\n","    \n","## <font color=\"blue\">Avaliação Solução</font>\n","\n","**Material Produzido por Luis Gustavo Nonato**<br>\n","**Cemeai - ICMC/USP São Carlos**\n","---"]},{"cell_type":"markdown","metadata":{"id":"F5LNoB1GLwiZ"},"source":["Os exercícios abaixo fazem uso da coleção de documentos presente no diretório `DocCol2` contido no arquivo <font style=\"font-family: monaco\"> DocCol.zip</font>, o qual pode ser baixado do Moodle."]},{"cell_type":"code","metadata":{"id":"cZAvsS5xLwiZ"},"source":["import os\n","import glob\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import pandas as pd\n","import numpy as np\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGYpNPWHLwia"},"source":["### Exercício 1)\n","Armazene os documentos disponíveis no diretório `DocCol2` em um dicionário onde a chave é o nome do arquivo e o valor é a string contida no arquivo. O documento contendo a string com o maior número de caracteres é:\n","\n","a) gr7<br>\n","<font color='red'> b) au2 </font><br>\n","c) ch5<br>\n","d) au8"]},{"cell_type":"code","metadata":{"id":"dWYn-au_Lwia","outputId":"c65b4b19-0389-4adc-fba4-9ff83fca52d0"},"source":["files = glob.glob(\"DocCol2/*\")\n","\n","docs = {}\n","larger_doc = ('',0)\n","for fname in files:\n","    with open(fname,'r') as f:\n","        key = fname.split(os.sep)[-1]\n","        docs[key] = f.read() \n","        if (len(docs[key]) > larger_doc[1]):\n","            larger_doc = (key,len(docs[key]))\n","        \n","print('Maior documento é: ',larger_doc[0],' com ',larger_doc[1],' caracteres')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Maior documento é:  au2  com  11672  caracteres\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ugfQSOUtLwib"},"source":["### Exercício 2)\n","Crie um dicionário chamado `docsXwords` onde as chaves são os nomes dos arquivos e os valores são as listas de palavras do documento correspondente. As palavras em cada uma das listas devem ser constituídas apenas por letras do alfabeto, estarem lexicamente normalizadas e conterem mais que 1 caracter. Qual o documento cuja lista de palavras resultante possui o **maior** número de palavras (lexicamente normalizadas) repetidas:\n","\n","a) gr22<br>\n","<font color='red'> b) ch30 </font><br>\n","c) au1<br>\n","d) au8"]},{"cell_type":"code","metadata":{"id":"-6Bmn28BLwib","outputId":"b1fd9c7f-5737-4b7c-a07d-74ba941efbc9"},"source":["docsXwords = {}\n","for key, value in docs.items():\n","    words = nltk.word_tokenize(value)\n","    words = [w.lower() for w in words if w.isalpha() and len(w) != 1]\n","    words = [PorterStemmer().stem(w) for w in words]\n","    docsXwords[key] = words\n","    \n","d={}\n","for key,value in docsXwords.items():\n","    nantes = len(value)\n","    ndepois = len(list(set(value))) \n","    d[key] = nantes - ndepois # a diferenca é o numero de\n","                              # de palavras repetidas\n","    \n","dsorted = sorted(d.items(), key=lambda x: x[1], reverse=True)\n","print(dsorted[:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('ch30', 1135), ('au2', 1122), ('ch24', 1032), ('gr23', 1016), ('ch21', 1005)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mZpsg6EHLwib"},"source":["### Exercício 3)\n","Utilizando as listas de palavras do dicionário `docsXwords`, quais as três palavras que mais aparecem na coleção de documentos:\n","\n","a) the, is, of<br>\n","b) that, is, of<br>\n","<font color='red'> c) the, of, to </font><br>\n","d) to, is, of"]},{"cell_type":"code","metadata":{"id":"uPf8YoAQLwic","outputId":"4952262a-4045-4f7c-bf1a-41b2bd46453f"},"source":["# unificando todas as palavras em uma única lista\n","corpus = [palavras for sublista in list(docsXwords.values()) for palavras in sublista]\n","\n","d = dict(Counter(corpus))\n","dsorted = sorted(d.items(), key=lambda x: x[1], reverse=True)\n","print(dsorted[:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('the', 5014), ('of', 2627), ('to', 2611), ('and', 2094), ('is', 1767)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fmLb7AQKLwic"},"source":["### Exercício 4)\n","Qual o documento cuja lista de palavras possui o **menor** número de \"stop words\"? Quantas \"stop words\" aparecem neste documento:\n","\n","<font color='red'> a) gr5 com 47 \"stop words\" </font><br>\n","b) gr17 com 47 \"stop words\"<br>\n","c) gr5 com 37 \"stop words\"<br>\n","d) gr17 com 37 \"stop words\"\n","\n","**Dica**: Crie um dicionário a partir de docsXwords onde a chave é o nome do documento e o valor o número de stop words no documento."]},{"cell_type":"code","metadata":{"id":"oVkiBR9sLwic","outputId":"e3bd916b-4fbf-482d-88f2-31256afead8e"},"source":["# lista das stop words\n","stop_words = stopwords.words('english')\n","\n","d={}\n","for key,value in docsXwords.items():\n","    nantes = len(value)\n","    ndepois = len([w for w in value if w not in stop_words]) \n","    d[key] = nantes - ndepois  # número de stop words\n","    \n","        \n","dsorted = sorted(d.items(), key=lambda x: x[1], reverse=True)\n","print(dsorted[-5:])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('gr13', 130), ('gr7', 99), ('gr12', 69), ('gr17', 68), ('gr5', 47)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l8Rpdw-jLwid"},"source":["### Exercício 5) \n","Utilize o dicionário `docsXwords` para construir\n","uma matriz Documentos $\\times$ Palavras para a coleção de documentos do diretório `DocCol2`. Utilizando a distância cosseno, qual é o documento mais parecido com o documento 'ch7':\n","\n","a) ch8<br>\n","<font color='red'> b) ch16 </font><br>\n","c) ch5<br>\n","d) au8"]},{"cell_type":"code","metadata":{"id":"jflBWszLLwid","outputId":"bf16e745-66d5-4a7a-adc7-764f9b70bbc7"},"source":["# unificando todas as palavras em uma única lista\n","corpus = [palavras for sublista in list(docsXwords.values()) for palavras in sublista]\n","\n","# removendo repeticoes\n","corpus = list(set(corpus))\n","\n","df_dXp = pd.DataFrame(data=np.zeros((len(list(docs.keys())),len(corpus))),\n","                      index = list(docs.keys()), columns = corpus)\n","\n","for key,value in docsXwords.items():\n","    dtemp = dict(Counter(value))\n","    df_dXp.loc[key,list(dtemp.keys())] = list(dtemp.values())\n","    \n","print(df_dXp.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["      outrun  armenian  odditi  jerkiu  petri  obstacl  gillespi  deuteronomi  \\\n","ch9      0.0       0.0     0.0     0.0    4.0      1.0       0.0          0.0   \n","ch38     0.0       0.0     0.0     0.0    0.0      0.0       0.0          0.0   \n","ch31     0.0       0.0     0.0     0.0    0.0      0.0       0.0          0.0   \n","ch7      0.0       0.0     0.0     0.0    0.0      0.0       0.0          0.0   \n","ch36     0.0       0.0     0.0     0.0    0.0      0.0       0.0          0.0   \n","\n","      dificult  uummmph  ...  triumph  bryan   le  firm  bumper  found  \\\n","ch9        0.0      0.0  ...      0.0    0.0  0.0   0.0     0.0    2.0   \n","ch38       0.0      0.0  ...      0.0    0.0  0.0   0.0     0.0    0.0   \n","ch31       0.0      0.0  ...      0.0    0.0  0.0   0.0     0.0    0.0   \n","ch7        0.0      0.0  ...      0.0    0.0  0.0   0.0     0.0    0.0   \n","ch36       0.0      0.0  ...      0.0    0.0  0.0   0.0     0.0    0.0   \n","\n","      miller  fairi  eye  burlesqu  \n","ch9      0.0    0.0  0.0       0.0  \n","ch38     0.0    0.0  0.0       0.0  \n","ch31     0.0    0.0  0.0       1.0  \n","ch7      0.0    0.0  0.0       0.0  \n","ch36     0.0    0.0  0.0       0.0  \n","\n","[5 rows x 6880 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXOMfSJdLwid","outputId":"98c40553-c9c7-4fa8-9004-8e6580ab2dfb"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","d_id = np.argwhere(df_dXp.index.values=='ch7')[0][0]\n","\n","X = df_dXp.values\n","X = StandardScaler().fit_transform(X)\n","\n","# calculando o cosseno utilizando a formula\n","# cos(x,y) = np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n","cos = np.apply_along_axis(lambda x: \n","             np.dot(X[d_id],x)/(np.linalg.norm(d_id)*np.linalg.norm(x)),1,X)\n","\n","sim_d_id = np.argsort(cos)[-2]\n","print('Documento mais parecido com ch7: ',df_dXp.index.values[sim_d_id])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Documento mais parecido com ch7:  ch16\n"],"name":"stdout"}]}]}